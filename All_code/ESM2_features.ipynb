{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJP0JmBW36n7iP46h52vsE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nhMvwnj2MTAK"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from Bio import SeqIO\n","import torch\n","import esm\n","\n","# Set random seeds for reproducibility\n","random_seed = 42\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","torch.cuda.manual_seed_all(random_seed)\n","np.random.seed(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# Check if GPU is available and set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Using device: {device}')\n","\n","# Read FASTA files and assign labels\n","def read_fasta_and_label(file_path, label):\n","    sequences = []\n","    labels = []\n","    for record in SeqIO.parse(file_path, \"fasta\"):\n","        sequences.append(str(record.seq))\n","        labels.append(label)\n","    return pd.DataFrame({'sequence': sequences, 'label': labels})\n","\n","# Load positive and negative sequences\n","positive_df = read_fasta_and_label('/content/sample_data/clustered_positive_0.4.fasta', 1)\n","negative_df = read_fasta_and_label('/content/sample_data/clustered_negative_0.4.fasta', 0)\n","\n","# Combine and shuffle the data\n","data = pd.concat([positive_df, negative_df]).sample(frac=1, random_state=random_seed).reset_index(drop=True)\n","print(f'Number of positive samples: {len(positive_df)}')\n","print(f'Number of negative samples: {len(negative_df)}')\n","\n","# Load ESM model\n","model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n","model = model.to(device)  # Move the model to the GPU\n","batch_converter = alphabet.get_batch_converter()\n","\n","# Function to extract ESM features\n","def extract_esm_features(sequences):\n","    data = [(\"seq\"+str(i), seq) for i, seq in enumerate(sequences)]\n","    batch_labels, batch_strs, batch_tokens = batch_converter(data)\n","    batch_tokens = batch_tokens.to(device)  # Move the tokens to the GPU\n","    with torch.no_grad():\n","        results = model(batch_tokens, repr_layers=[6])\n","    token_representations = results[\"representations\"][6]\n","    return token_representations.mean(1).cpu().numpy()  # Get the mean representation for each sequence\n","\n","# Extract ESM features for all sequences in the dataset\n","data['esm_features'] = data['sequence'].apply(lambda x: extract_esm_features([x])[0])\n","\n","# Convert ESM features to a format suitable for saving\n","X = np.vstack(data['esm_features'].values)\n","y = data['label'].values\n","\n","# Save features and labels to files\n","np.save('esm_features.npy', X)\n","np.save('labels.npy', y)\n","\n","print(\"ESM features and labels have been saved locally.\")\n"]}]}