{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM54ChtVBfeBDKLszbgiUGI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"t4V-uWc3JsOh"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix, classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Set random seeds for reproducibility\n","random_seed = 42\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","torch.cuda.manual_seed_all(random_seed)\n","np.random.seed(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# Check if GPU is available and set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Using device: {device}')\n","\n","# Load features and labels from Google Drive\n","X = np.load('/content/drive/MyDrive/esm_features_35M.npy')\n","y = np.load('/content/drive/MyDrive/labels_35M.npy')\n","\n","# Split the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_seed)\n","\n","# Reshape the features for LSTM input (e.g., (num_samples, seq_len, feature_dim))\n","seq_len = 1  # This should match your sequence length if it's different\n","X_train = X_train.reshape(-1, seq_len, X_train.shape[1])\n","X_test = X_test.reshape(-1, seq_len, X_test.shape[1])\n","\n","# Convert to PyTorch tensors\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.long)\n","y_test = torch.tensor(y_test, dtype=torch.long)\n","\n","# Create DataLoader\n","train_dataset = TensorDataset(X_train, y_train)\n","test_dataset = TensorDataset(X_test, y_test)\n","\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","class ImprovedLSTMClassifier(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, dropout_rate):\n","        super(ImprovedLSTMClassifier, self).__init__()\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_rate, bidirectional=True)\n","        self.bn = nn.BatchNorm1d(hidden_dim * 2)\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=76, kernel_size=(6, 1), padding=(1, 0))\n","        self.bn1 = nn.BatchNorm2d(76)\n","        self.pool = nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1))\n","        self.conv2 = nn.Conv2d(in_channels=76, out_channels=111, kernel_size=(4, 1), padding=(1, 0))\n","        self.bn2 = nn.BatchNorm2d(111)\n","        self.conv3 = nn.Conv2d(in_channels=111, out_channels=487, kernel_size=(5, 1), padding=(1, 0))\n","        self.bn3 = nn.BatchNorm2d(487)\n","\n","        self.flatten_dim = self._get_flatten_dim(input_dim)\n","        self.fc = nn.Linear(self.flatten_dim, num_classes)\n","        self.dropout = nn.Dropout(0.5456158649892608)\n","\n","    def _get_flatten_dim(self, input_dim):\n","        h0 = torch.zeros(num_layers * 2, batch_size, hidden_dim)\n","        c0 = torch.zeros(num_layers * 2, batch_size, hidden_dim)\n","        x = torch.ones(batch_size, 1, input_dim)\n","        out, _ = self.lstm(x, (h0, c0))\n","        out = out[:, -1, :]\n","        out = out.unsqueeze(1).unsqueeze(-1)\n","        out = self.conv1(out)\n","        out = self.bn1(out)\n","        out = F.relu(out)\n","        out = self.pool(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = F.relu(out)\n","        out = self.pool(out)\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        out = F.relu(out)\n","        out = self.pool(out)\n","        out = out.view(out.size(0), -1)\n","        return out.size(1)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.lstm.num_layers * 2, x.size(0), self.lstm.hidden_size).to(device)\n","        c0 = torch.zeros(self.lstm.num_layers * 2, x.size(0), self.lstm.hidden_size).to(device)\n","        out, _ = self.lstm(x, (h0, c0))\n","        out = out[:, -1, :]\n","        out = out.unsqueeze(1).unsqueeze(-1)\n","        out = self.conv1(out)\n","        out = self.bn1(out)\n","        out = F.relu(out)\n","        out = self.pool(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = F.relu(out)\n","        out = self.pool(out)\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        out = F.relu(out)\n","        out = self.pool(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.dropout(out)\n","        out = self.fc(out)\n","        return F.log_softmax(out, dim=1)\n","\n","# Initialize the improved LSTM model with the best hyperparameters\n","input_dim = X_train.shape[2]\n","hidden_dim = 181\n","num_layers = 4\n","dropout_rate = 0.4397133138964481\n","learning_rate = 0.0003466440190079221\n","num_classes = 2\n","\n","model = ImprovedLSTMClassifier(input_dim, hidden_dim, num_layers, num_classes, dropout_rate).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","n_epochs = 50\n","patience = 5\n","best_val_acc = 0.0\n","early_stop_counter = 0\n","\n","for epoch in range(n_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    correct = 0\n","    total = 0\n","    for data, target in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{n_epochs}\", leave=False):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * data.size(0)\n","        _, predicted = torch.max(output, 1)\n","        correct += (predicted == target).sum().item()\n","        total += target.size(0)\n","\n","    train_loss /= total\n","    train_accuracy = correct / total\n","\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data, target in tqdm(test_loader, desc=f\"Validating Epoch {epoch+1}/{n_epochs}\", leave=False):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = criterion(output, target)\n","            val_loss += loss.item() * data.size(0)\n","            _, predicted = torch.max(output, 1)\n","            correct += (predicted == target).sum().item()\n","            total += target.size(0)\n","\n","    val_loss /= total\n","    val_accuracy = correct / total\n","\n","    print(f'Epoch {epoch+1}/{n_epochs}')\n","    print(f'Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n","    print(f'Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    if val_accuracy > best_val_acc:\n","        best_val_acc = val_accuracy\n","        early_stop_counter = 0\n","        model_save_path = '/content/drive/MyDrive/best_improved_lstmCNN_model_35M.pth'\n","        torch.save(model.state_dict(), model_save_path)\n","        print(\"  Best model saved to Google Drive!\")\n","    else:\n","        early_stop_counter += 1\n","        if early_stop_counter >= patience:\n","            print(\"Early stopping triggered\")\n","            break\n","\n","# Load the best model\n","print(\"Loading the best model from Google Drive...\")\n","model.load_state_dict(torch.load('/content/drive/MyDrive/best_improved_lstmCNN_model_35M.pth'))\n","\n","# Evaluate on the test set\n","model.eval()\n","correct = 0\n","total = 0\n","y_pred_prob = []\n","y_true = []\n","\n","print(\"Evaluating on the test set...\")\n","with torch.no_grad():\n","    for data, target in tqdm(test_loader, desc=\"Testing\", leave=False):\n","        data, target = data.to(device), target.to(device)\n","        output = model(data)\n","        _, predicted = torch.max(output, 1)\n","        correct += (predicted == target).sum().item()\n","        y_pred_prob.extend(output[:, 1].cpu().numpy())\n","        y_true.extend(target.cpu().numpy())\n","\n","test_accuracy = correct / len(test_loader.dataset)\n","print(f'Test Accuracy: {test_accuracy:.4f}')\n","\n","# Calculate additional metrics\n","roc_auc = roc_auc_score(y_true, y_pred_prob)\n","fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n","precision, recall, _ = precision_recall_curve(y_true, y_pred_prob)\n","\n","# Plot Confusion Matrix\n","y_pred = np.argmax(model(torch.tensor(X_test, dtype=torch.float32).to(device)).cpu().detach().numpy(), axis=1)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","# Classification Report\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","\n","# ROC Curve and AUC\n","plt.figure(figsize=(12, 6))\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic')\n","plt.legend(loc='lower right')\n","plt.show()\n","\n","# Precision-Recall Curve\n","plt.figure(figsize=(12, 6))\n","plt.plot(recall, precision, color='blue', lw=2)\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall Curve')\n","plt.show()\n","\n"]},{"cell_type":"code","source":["import optuna\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix, classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Set random seeds for reproducibility\n","random_seed = 42\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","torch.cuda.manual_seed_all(random_seed)\n","np.random.seed(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# Check if GPU is available and set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Using device: {device}')\n","\n","# Load features and labels from Google Drive\n","X = np.load('/content/drive/MyDrive/esm_features_35M.npy')\n","y = np.load('/content/drive/MyDrive/labels_35M.npy')\n","\n","# Split the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_seed)\n","\n","# Reshape the features for LSTM input (e.g., (num_samples, seq_len, feature_dim))\n","seq_len = 1  # This should match your sequence length if it's different\n","X_train = X_train.reshape(-1, seq_len, X_train.shape[1])\n","X_test = X_test.reshape(-1, seq_len, X_test.shape[1])\n","\n","# Convert to PyTorch tensors\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.long)\n","y_test = torch.tensor(y_test, dtype=torch.long)\n","\n","# Create DataLoader\n","train_dataset = TensorDataset(X_train, y_train)\n","test_dataset = TensorDataset(X_test, y_test)\n","\n","def objective(trial):\n","    # Suggest hyperparameters\n","    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n","    num_layers = trial.suggest_int('num_layers', 1, 4)\n","    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n","    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n","    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    class ImprovedLSTMClassifier(nn.Module):\n","        def __init__(self, input_dim, hidden_dim, num_layers, num_classes, dropout_rate):\n","            super(ImprovedLSTMClassifier, self).__init__()\n","            self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_rate, bidirectional=True)\n","            self.bn = nn.BatchNorm1d(hidden_dim * 2)\n","            self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3, 1), padding=(1, 0))\n","            self.bn1 = nn.BatchNorm2d(64)\n","            self.pool = nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1))\n","            self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 1), padding=(1, 0))\n","            self.bn2 = nn.BatchNorm2d(128)\n","            self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 1), padding=(1, 0))\n","            self.bn3 = nn.BatchNorm2d(256)\n","\n","            self.flatten_dim = self._get_flatten_dim(input_dim)\n","            self.fc = nn.Linear(self.flatten_dim, num_classes)\n","            self.dropout = nn.Dropout(dropout_rate)\n","\n","        def _get_flatten_dim(self, input_dim):\n","            h0 = torch.zeros(num_layers * 2, batch_size, hidden_dim)\n","            c0 = torch.zeros(num_layers * 2, batch_size, hidden_dim)\n","            x = torch.ones(batch_size, 1, input_dim)\n","            out, _ = self.lstm(x, (h0, c0))\n","            out = out[:, -1, :]\n","            out = out.unsqueeze(1).unsqueeze(-1)\n","            out = self.conv1(out)\n","            out = self.bn1(out)\n","            out = F.relu(out)\n","            out = self.pool(out)\n","            out = self.conv2(out)\n","            out = self.bn2(out)\n","            out = F.relu(out)\n","            out = self.pool(out)\n","            out = self.conv3(out)\n","            out = self.bn3(out)\n","            out = F.relu(out)\n","            out = self.pool(out)\n","            out = out.view(out.size(0), -1)\n","            return out.size(1)\n","\n","        def forward(self, x):\n","            h0 = torch.zeros(self.lstm.num_layers * 2, x.size(0), self.lstm.hidden_size).to(device)\n","            c0 = torch.zeros(self.lstm.num_layers * 2, x.size(0), self.lstm.hidden_size).to(device)\n","            out, _ = self.lstm(x, (h0, c0))\n","            out = out[:, -1, :]\n","            out = out.unsqueeze(1).unsqueeze(-1)\n","            out = self.conv1(out)\n","            out = self.bn1(out)\n","            out = F.relu(out)\n","            out = self.pool(out)\n","            out = self.conv2(out)\n","            out = self.bn2(out)\n","            out = F.relu(out)\n","            out = self.pool(out)\n","            out = self.conv3(out)\n","            out = self.bn3(out)\n","            out = F.relu(out)\n","            out = self.pool(out)\n","            out = out.view(out.size(0), -1)\n","            out = self.dropout(out)\n","            out = self.fc(out)\n","            return F.log_softmax(out, dim=1)\n","\n","    input_dim = X_train.shape[2]\n","    num_classes = 2\n","\n","    model = ImprovedLSTMClassifier(input_dim, hidden_dim, num_layers, num_classes, dropout_rate).to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    n_epochs = 50\n","    patience = 5\n","    best_val_acc = 0.0\n","    early_stop_counter = 0\n","\n","    for epoch in range(n_epochs):\n","        model.train()\n","        train_loss = 0.0\n","        correct = 0\n","        total = 0\n","        for data, target in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{n_epochs}\", leave=False):\n","            data, target = data.to(device), target.to(device)\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item() * data.size(0)\n","            _, predicted = torch.max(output, 1)\n","            correct += (predicted == target).sum().item()\n","            total += target.size(0)\n","\n","        train_loss /= total\n","        train_accuracy = correct / total\n","\n","        model.eval()\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for data, target in tqdm(test_loader, desc=f\"Validating Epoch {epoch+1}/{n_epochs}\", leave=False):\n","                data, target = data.to(device), target.to(device)\n","                output = model(data)\n","                loss = criterion(output, target)\n","                val_loss += loss.item() * data.size(0)\n","                _, predicted = torch.max(output, 1)\n","                correct += (predicted == target).sum().item()\n","                total += target.size(0)\n","\n","        val_loss /= total\n","        val_accuracy = correct / total\n","\n","        print(f'Epoch {epoch+1}/{n_epochs}')\n","        print(f'Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n","        print(f'Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","        if val_accuracy > best_val_acc:\n","            best_val_acc = val_accuracy\n","            early_stop_counter = 0\n","            model_save_path = '/content/drive/MyDrive/best_improved_lstmCNN_model_35M.pth'\n","            torch.save(model.state_dict(), model_save_path)\n","            print(\"  Best model saved to Google Drive!\")\n","        else:\n","            early_stop_counter += 1\n","            if early_stop_counter >= patience:\n","                print(\"Early stopping triggered\")\n","                break\n","\n","    return best_val_acc  # Return validation accuracy for optimization\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=50)\n","\n","# Step 4: Print the Best Hyperparameters\n","print('Best hyperparameters:', study.best_params)\n","print('Best Accuracy score:', study.best_value)\n","\n","# Load the best model\n","print(\"Loading the best model from Google Drive...\")\n","model.load_state_dict(torch.load('/content/drive/MyDrive/best_improved_lstmCNN_model_35M.pth'))\n","\n","# Evaluate on the test set\n","model.eval()\n","correct = 0\n","total = 0\n","y_pred_prob = []\n","y_true = []\n","\n","print(\"Evaluating on the test set...\")\n","with torch.no_grad():\n","    for data, target in tqdm(test_loader, desc=\"Testing\", leave=False):\n","        data, target = data.to(device), target.to(device)\n","        output = model(data)\n","        _, predicted = torch.max(output, 1)\n","        correct += (predicted == target).sum().item()\n","        y_pred_prob.extend(output[:, 1].cpu().numpy())\n","        y_true.extend(target.cpu().numpy())\n","\n","test_accuracy = correct / len(test_loader.dataset)\n","print(f'Test Accuracy: {test_accuracy:.4f}')\n","\n","# Calculate additional metrics\n","roc_auc = roc_auc_score(y_true, y_pred_prob)\n","fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n","precision, recall, _ = precision_recall_curve(y_true, y_pred_prob)\n","\n","# Plot Confusion Matrix\n","y_pred = np.argmax(model(torch.tensor(X_test, dtype=torch.float32).to(device)).cpu().detach().numpy(), axis=1)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","# Classification Report\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","\n","# ROC Curve and AUC\n","plt.figure(figsize=(12, 6))\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic')\n","plt.legend(loc='lower right')\n","plt.show()\n","\n","# Precision-Recall Curve\n","plt.figure(figsize=(12, 6))\n","plt.plot(recall, precision, color='blue', lw=2)\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall Curve')\n","plt.show()\n"],"metadata":{"id":"NoL8eNYTKK5b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset, Subset\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix, classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Set random seeds for reproducibility\n","random_seed = 42\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","torch.cuda.manual_seed_all(random_seed)\n","np.random.seed(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# Check if GPU is available and set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Using device: {device}')\n","\n","# Load features and labels from Google Drive\n","X = np.load('/content/drive/MyDrive/esm_features_35M.npy')\n","y = np.load('/content/drive/MyDrive/labels_35M.npy')\n","\n","# Reshape the features for LSTM input (e.g., (num_samples, seq_len, feature_dim))\n","seq_len = 1  # This should match your sequence length if it's different\n","X = X.reshape(-1, seq_len, X.shape[1])\n","\n","# Convert to PyTorch tensors\n","X_tensor = torch.tensor(X, dtype=torch.float32)\n","y_tensor = torch.tensor(y, dtype=torch.long)\n","\n","# Create TensorDataset\n","dataset = TensorDataset(X_tensor, y_tensor)\n","\n","# Initialize parameters\n","input_dim = X.shape[2]\n","hidden_dim = 181\n","num_layers = 4\n","dropout_rate = 0.4397133138964481\n","learning_rate = 0.0003466440190079221\n","num_classes = 2\n","batch_size = 32\n","n_epochs = 50\n","patience = 5\n","\n","# Initialize KFold\n","kf = KFold(n_splits=10, shuffle=True, random_state=random_seed)\n","\n","# Define model class\n","class ImprovedLSTMClassifier(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, dropout_rate):\n","        super(ImprovedLSTMClassifier, self).__init__()\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_rate, bidirectional=True)\n","        self.bn = nn.BatchNorm1d(hidden_dim * 2)\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=76, kernel_size=(6, 1), padding=(1, 0))\n","        self.bn1 = nn.BatchNorm2d(76)\n","        self.pool = nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1))\n","        self.conv2 = nn.Conv2d(in_channels=76, out_channels=111, kernel_size=(4, 1), padding=(1, 0))\n","        self.bn2 = nn.BatchNorm2d(111)\n","        self.conv3 = nn.Conv2d(in_channels=111, out_channels=487, kernel_size=(5, 1), padding=(1, 0))\n","        self.bn3 = nn.BatchNorm2d(487)\n","\n","        self.flatten_dim = self._get_flatten_dim(input_dim)\n","        self.fc = nn.Linear(self.flatten_dim, num_classes)\n","        self.dropout = nn.Dropout(0.5456158649892608)\n","\n","    def _get_flatten_dim(self, input_dim):\n","        h0 = torch.zeros(num_layers * 2, batch_size, hidden_dim)\n","        c0 = torch.zeros(num_layers * 2, batch_size, hidden_dim)\n","        x = torch.ones(batch_size, 1, input_dim)\n","        out, _ = self.lstm(x, (h0, c0))\n","        out = out[:, -1, :]\n","        out = out.unsqueeze(1).unsqueeze(-1)\n","        out = self.conv1(out)\n","        out = self.bn1(out)\n","        out = F.relu(out)\n","        out = self.pool(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = F.relu(out)\n","        out = self.pool(out)\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        out = F.relu(out)\n","        out = self.pool(out)\n","        out = out.view(out.size(0), -1)\n","        return out.size(1)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.lstm.num_layers * 2, x.size(0), self.lstm.hidden_size).to(device)\n","        c0 = torch.zeros(self.lstm.num_layers * 2, x.size(0), self.lstm.hidden_size).to(device)\n","        out, _ = self.lstm(x, (h0, c0))\n","        out = out[:, -1, :]\n","        out = out.unsqueeze(1).unsqueeze(-1)\n","        out = self.conv1(out)\n","        out = self.bn1(out)\n","        out = F.relu(out)\n","        out = self.pool(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = F.relu(out)\n","        out = self.pool(out)\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        out = F.relu(out)\n","        out = self.pool(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.dropout(out)\n","        out = self.fc(out)\n","        return F.log_softmax(out, dim=1)\n","\n","# Cross-validation\n","fold = 1\n","accuracies = []\n","for train_idx, val_idx in kf.split(dataset):\n","    print(f\"Training fold {fold}/{kf.n_splits}\")\n","\n","    # Create data loaders for this fold\n","    train_subset = Subset(dataset, train_idx)\n","    val_subset = Subset(dataset, val_idx)\n","    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n","\n","    # Initialize the model, loss function, and optimizer\n","    model = ImprovedLSTMClassifier(input_dim, hidden_dim, num_layers, num_classes, dropout_rate).to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    best_val_acc = 0.0\n","    early_stop_counter = 0\n","\n","    for epoch in range(n_epochs):\n","        model.train()\n","        train_loss = 0.0\n","        correct = 0\n","        total = 0\n","        for data, target in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{n_epochs}\", leave=False):\n","            data, target = data.to(device), target.to(device)\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item() * data.size(0)\n","            _, predicted = torch.max(output, 1)\n","            correct += (predicted == target).sum().item()\n","            total += target.size(0)\n","\n","        train_loss /= total\n","        train_accuracy = correct / total\n","\n","        model.eval()\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for data, target in tqdm(val_loader, desc=f\"Validating Epoch {epoch+1}/{n_epochs}\", leave=False):\n","                data, target = data.to(device), target.to(device)\n","                output = model(data)\n","                loss = criterion(output, target)\n","                val_loss += loss.item() * data.size(0)\n","                _, predicted = torch.max(output, 1)\n","                correct += (predicted == target).sum().item()\n","                total += target.size(0)\n","\n","        val_loss /= total\n","        val_accuracy = correct / total\n","\n","        print(f'Epoch {epoch+1}/{n_epochs}')\n","        print(f'Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n","        print(f'Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","        if val_accuracy > best_val_acc:\n","            best_val_acc = val_accuracy\n","            early_stop_counter = 0\n","            model_save_path = f'/content/drive/MyDrive/FinalTest/best_lstmCNN_model_fold_{fold}.pth'\n","            torch.save(model.state_dict(), model_save_path)\n","            print(f\"  Best model for fold {fold} saved to Google Drive!\")\n","        else:\n","            early_stop_counter += 1\n","            if early_stop_counter >= patience:\n","                print(\"Early stopping triggered\")\n","                break\n","\n","    # Load the best model for this fold\n","    print(f\"Loading the best model for fold {fold} from Google Drive...\")\n","    model.load_state_dict(torch.load(f'/content/drive/MyDrive/FinalTest/best_lstmCNN_model_fold_{fold}.pth'))\n","\n","    # Evaluate on the validation set\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    y_pred_prob = []\n","    y_true = []\n","\n","    print(f\"Evaluating fold {fold} on the validation set...\")\n","    with torch.no_grad():\n","        for data, target in tqdm(val_loader, desc=\"Testing\", leave=False):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            _, predicted = torch.max(output, 1)\n","            correct += (predicted == target).sum().item()\n","            y_pred_prob.extend(output[:, 1].cpu().numpy())\n","            y_true.extend(target.cpu().numpy())\n","\n","    val_accuracy = correct / len(val_loader.dataset)\n","    accuracies.append(val_accuracy)\n","    print(f'Validation Accuracy for fold {fold}: {val_accuracy:.4f}')\n","    fold += 1\n","\n","# Print final cross-validated accuracy\n","mean_accuracy = np.mean(accuracies)\n","std_accuracy = np.std(accuracies)\n","print(f'Final Cross-Validated Accuracy: {mean_accuracy:.4f} Â± {std_accuracy:.4f}')\n"],"metadata":{"id":"Fi_dE3bDKAkp"},"execution_count":null,"outputs":[]}]}